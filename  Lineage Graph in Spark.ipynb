{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef2d5e94",
   "metadata": {},
   "source": [
    "## What is Lineage Graph in Spark?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3b463a",
   "metadata": {},
   "source": [
    "The Lineage Graph is a directed acyclic graph (DAG) in Spark or PySpark that represents the dependencies between RDDs (Resilient Distributed Datasets) or DataFrames in a Spark application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161ae4a3",
   "metadata": {},
   "source": [
    "what is Lineage Graph in Spark/PySpark, and its properties, and illustrate the Lineage Graph with dependencies between RDDs with examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd3b991",
   "metadata": {},
   "source": [
    "### Lineage Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c879da",
   "metadata": {},
   "source": [
    "!['Lineage Graph'](lineageGraph.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365a055f",
   "metadata": {},
   "source": [
    "Every transformation in Spark creates a new RDD or DataFrame that is dependent on its parent RDDs or DataFrames. The Lineage Graph\n",
    "\n",
    "+ Tracks all the operations performed on the input data, including transformations and actions, and stores the metadata of the data transformation steps.\n",
    "\n",
    "+ It is a crucial component of Spark’s fault tolerance mechanism. Since RDDs are immutable, the Lineage Graph helps in reconstructing lost RDDs by recomputing their parent RDDs based on their transformations. This feature enables Spark to recover lost data in case of node failures or other issues in the cluster.\n",
    "\n",
    "+ This also helps in optimizing the execution plan of Spark applications. Spark uses the information in the Lineage Graph to optimize the DAG and perform transformations in a way that reduces data shuffling and increases parallelism. This optimization leads to faster execution times and efficient utilization of cluster resources.\n",
    "\n",
    "+ This can be visualized using the toDebugString() method in Spark. This method prints a string representation of the lineage graph, including the dependencies between RDDs and the transformations applied to each RDD.\n",
    "\n",
    "\n",
    "Overall, the Lineage Graph is a powerful and important component of Spark that enables fault tolerance, optimization, and efficient use of cluster resources. Understanding the Lineage Graph is crucial for developing efficient and fault-tolerant Spark applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de74315c",
   "metadata": {},
   "source": [
    "### Properties of Lineage Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baef7e58",
   "metadata": {},
   "source": [
    "\n",
    "**The Lineage Graph in Spark has the following properties:**\n",
    "\n",
    "+ Directed Acyclic Graph (DAG): The Lineage Graph is a directed acyclic graph, which means that it is a graph of vertices (RDDs or DataFrames) connected by directed edges that represent dependencies. It is acyclic because there are no circular dependencies between the vertices.\n",
    "\n",
    "+ Immutable: RDDs are immutable, meaning that once an RDD is created, it cannot be modified. This property is reflected in the Lineage Graph, which stores the lineage of each RDD as a series of transformations that were applied to the original data.\n",
    "\n",
    "+ Fault Tolerance: The Lineage Graph is used for Spark’s fault-tolerance mechanism. Since RDDs are immutable, Spark can recreate any lost RDDs by tracing them back to their parent RDDs and recomputing the transformations that were applied to them.\n",
    "\n",
    "+ Optimization: The Lineage Graph helps Spark optimize the execution plan of transformations by reducing data shuffling and increasing parallelism. This optimization leads to faster execution times and efficient utilization of cluster resources.\n",
    "\n",
    "+ Metadata: The Lineage Graph stores metadata about each RDD, including its data type, partitioning scheme, and dependencies. This information is used by Spark to optimize the execution plan and ensure that the correct transformations are applied to each RDD.\n",
    "\n",
    "Overall, the Lineage Graph is a powerful and important component of Spark that enables fault tolerance, optimization, and efficient use of cluster resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a34f27",
   "metadata": {},
   "source": [
    "### Demo of Linege Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c1d036",
   "metadata": {},
   "source": [
    "Let us try to create a sample RDD using the below data from a text file and apply word count logic to it and finally use **toDebugString** method on the wordCount RDD to get the representation of the lineage graph, including the dependencies between RDDs and the transformations applied to each RDD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2911009e",
   "metadata": {},
   "source": [
    "Sample Data:\n",
    "\n",
    "\n",
    "Hello world\n",
    "This is a test\n",
    "Test successful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450c868e",
   "metadata": {},
   "source": [
    "we create an RDD lines by reading the above sample data in a text file. We then apply two transformations to this RDD to split the lines into words and count the occurrence of each word. Finally, we perform an action by calling collect() to trigger the execution of the RDD lineage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef6f070c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Spark\\\\sparkhome'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6167040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfc63b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Vamsi_App\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82207125",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create an RDD from a text file\n",
    "lines = spark.sparkContext.textFile(\"input.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22dfad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply a transformation to the RDD\n",
    "words = lines.flatMap(lambda line: line.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e109e3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply another transformation to the RDD\n",
    "wordCounts = words.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faefcf7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Perform an action to trigger execution of the RDD lineage\n",
    "wordCounts.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b4e793",
   "metadata": {},
   "source": [
    "Now call The toDebugString method on the wordCounts RDD to print the lineage graph. This method prints a string representation of the lineage graph, including the dependencies between RDDs and the transformations applied to each RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "917356af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'(0) PythonRDD[8] at collect at C:\\\\Users\\\\durga.vamsikumar\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_32540\\\\4226705846.py:2 []\\n |  MapPartitionsRDD[7] at mapPartitions at PythonRDD.scala:158 []\\n |  ShuffledRDD[6] at partitionBy at NativeMethodAccessorImpl.java:0 []\\n +-(0) PairwiseRDD[5] at reduceByKey at C:\\\\Users\\\\durga.vamsikumar\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_32540\\\\1298829572.py:2 []\\n    |  PythonRDD[4] at reduceByKey at C:\\\\Users\\\\durga.vamsikumar\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_32540\\\\1298829572.py:2 []\\n    |  input.txt MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:0 []\\n    |  input.txt HadoopRDD[0] at textFile at NativeMethodAccessorImpl.java:0 []'\n"
     ]
    }
   ],
   "source": [
    "#Print the RDD lineage\n",
    "print(wordCounts.toDebugString())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6675bb2b",
   "metadata": {},
   "source": [
    "This output shows the lineage graph for the wordCounts RDD. We can see that this RDD depends on an ReduceByKey operation, which in turn depends on a MapPartitionsRDD. These RDDs were created by applying transformations to the lines RDD, which was created from the input text file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8c3965",
   "metadata": {},
   "source": [
    "The DAG dependency between the RDDs transformations and actions is available in visualization format as well in Spark UI. Spark UI can be accessed using the http://localhost:4040/ . Spark UI by default runs on port 4040 and below are some of the additional UI’s that would be helpful to track the Spark application. Here is DAG in the Spark UI showing the lineage graph for the wordCounts RDD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4160c2",
   "metadata": {},
   "source": [
    "!['Flow path of RDD'](spark1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e834fd",
   "metadata": {},
   "source": [
    "We can see from the output, Each Wide Transformation results in a separate Number of Stages. In our case, Spark creates two Stages one for reading and MapPartitionsRDD the RDD and the other shuffle RDD for ReduceByKey operation. We can see that this RDD depends on an ReduceByKey operation(Stage1), which in turn depends on a MapPartitionsRDD(Stage0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8778e9cf",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dc84ba",
   "metadata": {},
   "source": [
    "\n",
    "In conclusion, the Lineage Graph is a key concept in Apache Spark that represents the dependencies between RDDs or DataFrames in a Spark application. The Lineage Graph helps in fault tolerance by reconstructing lost RDDs based on their parent RDDs and their transformations. It also optimizes the execution plan of Spark applications by reducing data shuffling and increasing parallelism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f0f33a",
   "metadata": {},
   "source": [
    "#### Reference Article: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a09fc7",
   "metadata": {},
   "source": [
    "##### Thanks to sparkbyexamples "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f895517",
   "metadata": {},
   "source": [
    "https://sparkbyexamples.com/spark/what-is-lineage-graph-in-spark/#h-1-what-is-spark-lineage-graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c6f876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
